{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "625b24e5-b6ff-4811-a635-f4b31df3b0e8",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2e77a231-c0ec-4774-90e3-d648ab27ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#pyclustering\n",
    "from pyclustering.cluster.kmedians import kmedians\n",
    "from pyclustering.cluster import cluster_visualizer\n",
    "from pyclustering.cluster.center_initializer import random_center_initializer\n",
    "\n",
    "#scipy\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import ward, fcluster\n",
    "\n",
    "#sklearn\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, tree, neighbors\n",
    "from sklearn import naive_bayes, ensemble\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "#warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697cf79b-cc4b-48d2-ab6d-86fdae746205",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f65751-43a1-4f44-8709-32eb0e02081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "airline = pd.read_csv('Airline_Passenger.csv')\n",
    "airline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e6ab0-4451-45a2-a7a2-74d151f2fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check columns\n",
    "airline.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782e9a18-908a-4af9-bb62-2f6f09edb1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "airline['satisfaction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152614d2-20bf-4558-a2b5-e0de1ca26fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape\n",
    "airline.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261b797a-b1fe-4a25-9771-7c8a3939bc2b",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342b359-2f5a-4e3c-9896-04f7ef2c1a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unnamed column\n",
    "airline = airline.drop(columns = ['Unnamed: 0', 'id']) #since not used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2122582-1165-48fc-b6e6-2b822fe60206",
   "metadata": {},
   "source": [
    "- data is very clean\n",
    "- not checking for null values , because Arrival Delay has 0 values = no delay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d95865-b1c2-4082-aec3-f880533b010c",
   "metadata": {},
   "source": [
    "### Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0055f7-0556-41b8-9a12-f269c17bb90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing values\n",
    "airline.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1da4f-7e3f-4294-9bf6-b5d59d9bab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in arrival Delay in Minutes na values = 0, meaning no delay\n",
    "#fill with 0\n",
    "airline['Arrival Delay in Minutes'].fillna(0, inplace = True)\n",
    "\n",
    "#check again\n",
    "airline.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da3127-7cac-4e8a-8023-019891fe9a28",
   "metadata": {},
   "source": [
    "### Converting categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b6c3f-5dfa-44b0-98db-74155d4c6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert Gender, Customer Type, Type of Travel, Class to categorical\n",
    "airline['Gender'] = airline['Gender'].astype('category')\n",
    "airline['Customer Type'] = airline['Customer Type'].astype('category')\n",
    "airline['Type of Travel'] = airline['Type of Travel'].astype('category')\n",
    "airline['satisfaction'] = airline['satisfaction'].astype('category')\n",
    "airline.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555a967-4b18-44a1-a493-bb996f5a07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for unique\n",
    "print(airline['Gender'].unique())\n",
    "print(airline['Customer Type'].unique())\n",
    "print(airline['Type of Travel'].unique())\n",
    "print(airline['Class'].unique())\n",
    "print(airline['satisfaction'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7978829f-1357-49e2-b643-84ff434acf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting them\n",
    "categorical_columns = airline.select_dtypes(['category']).columns\n",
    "categorical_columns\n",
    "airline[categorical_columns] = airline[categorical_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb84445-8f87-4c5e-94b0-ad1bf3929e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting class 0-2\n",
    "category_mapping = {'Eco': 0, 'Eco Plus': 1, 'Business': 2}\n",
    "airline['Class'] = airline['Class'].map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bca09b-b0a9-4b3a-812d-426a7148d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking\n",
    "print(airline['Gender'].unique())\n",
    "print(airline['Customer Type'].unique())\n",
    "print(airline['Type of Travel'].unique())\n",
    "print(airline['Class'].unique())\n",
    "print(airline['satisfaction'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927264d6-c891-4715-aa66-e9a4f9bc336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "airline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177f29c4-3c6d-4c16-822e-0c99c96cdf95",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e69637-ccc7-4a26-a18d-e0bc69c69f0e",
   "metadata": {},
   "source": [
    "## Distribution of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8346c73f-af2b-46f7-8bda-37eac7e5a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "sns.histplot(airline['Age'], bins = 20, kde = True, color = 'purple')\n",
    "plt.title('Distribution of Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e53e85b-f3a8-463e-ac42-942f574a2a30",
   "metadata": {},
   "source": [
    "## Count of Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe3b70-b73e-4101-93af-c8238d0cd0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='Gender', data=airline, palette='icefire')\n",
    "plt.title('Count of Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=[0, 1], labels=['Female', 'Male'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd7d85-7fc5-4001-acad-f6b3c472fdaa",
   "metadata": {},
   "source": [
    "## Age by Class & Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a8bd4-6994-47ed-9dca-edee986ab345",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Class', y='Age', hue='Gender', data=airline, palette = 'PuBuGn')\n",
    "plt.title('Age by Class and Gender: Female:0, Male:1')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd86a838-fd01-41d5-965c-7afd52646350",
   "metadata": {},
   "source": [
    "## Count of Customer Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c598b40-6d81-455b-a83d-4c9969f12583",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='Customer Type', data=airline, palette='cividis')\n",
    "plt.title('Count of Customer Type')\n",
    "plt.xlabel('Customer Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=[0, 1], labels=['Loyal', 'Disloyal'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86bd910-1e9d-475b-be3a-7fc536c17226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf9bdb-da26-4b1c-90d4-ff9f996d1434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e225997f-f1ac-49cc-91c9-6405e5bfcb31",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f548a0-9c8c-4bff-b9a2-8b6cb77a6f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = airline.corr()\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize = (25, 25))\n",
    "sns.heatmap(correlation_matrix, cmap = 'magma')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "#correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1079e-06f0-4a4c-b7bf-99aa8c8152de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae45eb-9bda-44cd-bc71-af692785d1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df845263-74da-40c0-9685-85d77855016a",
   "metadata": {},
   "source": [
    "# Overall model comparision for the entire data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894bb35e-834c-4900-8ee6-df54ad023c38",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91156928-f4c6-4d1c-80fa-3161ca571b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = airline.drop(['satisfaction'],axis = 1)\n",
    "y = airline['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eca9ef-203a-459f-8025-f9110686688d",
   "metadata": {},
   "source": [
    "### Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabad83-560b-4802-b5f0-41857df9505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "#calculate accuracy\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "print(\"Accuracy of Logistic Regression:\", accuracy_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f370dd-6e12-499f-bebb-dc838b6004cb",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6049699e-4994-4f7c-a159-60e6f7e8d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check which depth to use\n",
    "scores_list = []\n",
    "depth_list = np.arange(1,20,1)\n",
    "for depth in depth_list:\n",
    "    dt = DecisionTreeClassifier(max_depth = depth, criterion = 'gini', random_state = 0)\n",
    "    scores = cross_val_score(dt, X_train, y_train, cv = 10,scoring = 'accuracy')\n",
    "    scores_list.append(scores.mean())\n",
    "\n",
    "#plot\n",
    "plt.plot(depth_list, scores_list,  color = 'purple', markerfacecolor = 'black',label = 'Score')\n",
    "plt.title('Accuracy Score vs max_depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6826f1cd-ce55-4e01-a91b-8fd1d01024ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for max accuracy depth\n",
    "max_value = max(scores_list)\n",
    "max_index = scores_list.index(max_value)\n",
    "max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7bf789-fa3c-452e-b2d1-25d4abeed3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 13, criterion = \"gini\", random_state = 0)\n",
    "dt_model = dt.fit(X_train, y_train)\n",
    "\n",
    "#calculate accuracy\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Accuracy of Decision Tree:\", accuracy_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34b0177-decc-498b-bf81-173c23e9e737",
   "metadata": {},
   "source": [
    "### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcabe52-0db9-4553-b014-cf4322543c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0)\n",
    "clf_bag.fit(X_train_scaled, y_train)\n",
    "y_pred_bag = clf_bag.predict(X_test_scaled)\n",
    "\n",
    "#calculate accuracy\n",
    "accuracy_bag = accuracy_score(y_test, y_pred_bag)\n",
    "print(\"Accuracy of Bagging Classifier:\", accuracy_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713a2d2d-cb2d-4cea-a771-e181b950a023",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d6093-78cb-42f2-a625-620ea2f08e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rand_forest_model.fit(X_train, y_train)\n",
    "\n",
    "#calculate accuracy\n",
    "y_pred_rand_forest = rand_forest_model.predict(X_test)\n",
    "accuracy_rand_forest = accuracy_score(y_test, y_pred_rand_forest)\n",
    "print(\"Accuracy of Random Forest:\", accuracy_rand_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe39bfe-e84b-4798-8e5b-acd643c6186b",
   "metadata": {},
   "source": [
    "### GB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b655c1ad-4b91-4b33-bb7c-d208c8d54aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "#calculate accuracy\n",
    "y_pred_gbc = gbc.predict(X_test)\n",
    "accuracy_gbc = accuracy_score(y_test, y_pred_gbc)\n",
    "print(\"Accuracy of GB Classifier:\", accuracy_gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc27cb2-3a7b-4d38-92c4-f99633ba5b67",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d800ed5-b0dd-4905-b91a-6e082b27dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-means\n",
    "cluster_range = range(2,50)\n",
    "cluster_wss = []\n",
    "\n",
    "for num_cluster in cluster_range:\n",
    "    clusters = KMeans(num_cluster)\n",
    "    clusters.fit(X_train)\n",
    "    cluster_wss.append(clusters.inertia_)\n",
    "    \n",
    "plt.xlabel('# Clusters')\n",
    "plt.ylabel('WSS')\n",
    "plt.plot(cluster_range, cluster_wss, marker = 'o', color = 'purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc81888-9f00-4631-ac6d-dd7054e538d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "knn.fit(X, y)\n",
    "\n",
    "#calculate accuracy\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"Accuracy of KNN:\", accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578bca96-69c0-46ad-86b0-f03c138fe3fa",
   "metadata": {},
   "source": [
    "### Comparing all the models on overall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61859d61-17a0-4356-a5bd-2d0153824736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to keep decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state =0).fit(X_train, y_train)\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112bc719-4e73-4537-893b-635b5eac64d5",
   "metadata": {},
   "source": [
    "### Best model for overall data = Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed53360-5dec-4e6a-a2da-d2bab47cc2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f89c5cc-7466-443c-8859-586f79949cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b2fcc18-a1b7-4ce9-96e3-c87e39d9dc18",
   "metadata": {},
   "source": [
    "# Subsetting data by Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a4df4c-92e6-4c4c-ade2-4fa8dad7da24",
   "metadata": {},
   "source": [
    "## Business Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ebd84-21a2-41c0-83be-68e56876dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "business = airline[airline['Class'] == 2]\n",
    "business.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90dd4dd-c274-4042-bc8f-1d9d23419073",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c97e13a-2e63-4a37-828c-ec277459d2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = business.drop(['satisfaction'], axis = 1)\n",
    "y = business['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f61bfae-abe3-45c2-9717-90b5e08b4941",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0174f70-c3f7-4fbf-ab5b-e121805b2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion = 'gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f19a4c4-def3-4c2c-b85a-d9b96f7fb05b",
   "metadata": {},
   "source": [
    "### Best model for Business class data = Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad03fa6-cfc1-49ba-88a9-36bfb53c2d21",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf0aa3c-f557-47da-95e2-c52d1a524436",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rand_forest = rand_forest_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rand_forest, labels = rand_forest_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = rand_forest_model.classes_)\n",
    "disp.plot(cmap = 'flare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db64ca04-2cbb-4ae2-8009-e0c870704e27",
   "metadata": {},
   "source": [
    "## Economy Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9fa61d-6487-437b-9cb2-a11edb3a87bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy = airline[airline['Class'] == 0]\n",
    "economy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ea1ec-5a80-46df-bb40-381764cbe786",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7633e40-5c13-4b0c-9368-8beac6de5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = economy.drop(['satisfaction'], axis = 1)\n",
    "y = economy['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a78975-d02d-4ec7-af13-c1bfcf025157",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d7c564-d72b-49c3-b778-8d1e9e994311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3895fb26-a4a0-4803-8e26-f10aa0da1f93",
   "metadata": {},
   "source": [
    "### Best model for Economy Class data = Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f768fb1f-6999-4048-93fb-557f4e55261a",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f99afe-576d-4ed7-885e-0f309c287d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rand_forest = rand_forest_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rand_forest, labels = rand_forest_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = rand_forest_model.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb6b90-d098-4661-ae67-4883ed0e48e6",
   "metadata": {},
   "source": [
    "## Economy Plus Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242dfe73-f6e5-465c-a706-dc5053be6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy_plus = airline[airline['Class'] == 1]\n",
    "economy_plus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bcd24a-37ae-4de5-b5e3-8e8bf65e41ec",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f6d4ba-82ba-43ef-8c5c-abcfbf34b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = economy_plus.drop(['satisfaction'], axis = 1)\n",
    "y = economy_plus['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3955b5-3a06-4993-9bba-49f392493c49",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84afad19-3de6-4244-a7bb-3474e8c537d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275dad94-6dbb-4095-8905-26e1009152d3",
   "metadata": {},
   "source": [
    "### Best model for Economy Plus Class data = Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed9863-fbe5-43fe-9644-982fa79394c3",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e16c9-56eb-49c0-93c8-a0c51cfa0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gbc = gbc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_gbc, labels = gbc.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = gbc.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70252bc-ae3b-49ea-9e6e-a19261eaf0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde00311-0614-4322-be67-be5ad632d6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54e682a9-2b05-4a42-95fe-e37b56c75df4",
   "metadata": {},
   "source": [
    "# Subsetting data by Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e41c4a-7c77-4778-a42b-d151fea405cf",
   "metadata": {},
   "source": [
    "## Female data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dfba4f-695d-41d8-b132-f0881a0669d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "female = airline[airline['Gender'] == 0]\n",
    "female.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f4823-527a-46e6-86f1-677fa8630d4f",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd622c1e-350d-4929-962b-bc4f73a6b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = female.drop(['satisfaction'], axis = 1)\n",
    "y = female['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45053c2c-2a33-4fd0-8f71-200ca06cb0f6",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e51f5-6581-449f-a268-7fcb82ced814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ff4b8-dd73-4936-aa8b-e2d00d1ffb40",
   "metadata": {},
   "source": [
    "### Best model for Female data = Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627121a0-58b3-4b0e-a31c-dbb2f5dea4a6",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea57e1-24d3-4bf3-a6af-1332c3a5c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rand_forest = rand_forest_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rand_forest, labels = rand_forest_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = rand_forest_model.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14b15ec-7418-4246-af46-61e3367209b7",
   "metadata": {},
   "source": [
    "## Male data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a55964f-3358-4f8e-802e-0d065c741a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = airline[airline['Gender'] == 1]\n",
    "male.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b063fe-6720-4435-b3e4-c580365a7578",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22831701-fbc1-4c68-9a5c-11e46c5828d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = male.drop(['satisfaction'], axis = 1)\n",
    "y = male['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36edcf7b-8a4e-479c-bef4-af910ab1be84",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7c247-2d03-4ce7-ab0f-b46648d2464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02feca75-18a8-423f-be80-0d5665a03dc4",
   "metadata": {},
   "source": [
    "### Best model for Male data = Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17523815-c21a-486e-858f-63d9086913d8",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e15139-c98c-4fc0-9efc-fce9e0109289",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rand_forest = rand_forest_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rand_forest, labels = rand_forest_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = rand_forest_model.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f1ab0-ae34-48c8-991e-b5683f683f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91a5da-be93-47eb-a808-e0d3e5c07359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a0455b0-d2a6-4f9f-bc49-6b5c6257c0cb",
   "metadata": {},
   "source": [
    "# Subsetting data by Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a391d5-b0f4-4223-abf2-0b26e830a7d6",
   "metadata": {},
   "source": [
    "## Age group 1: 6 - 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f232f9-a3dd-411f-b2b5-d587cc498f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_1 = airline[(airline['Age'] > 6) & (airline['Age'] <= 18)]\n",
    "age_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a477ad2f-ab72-445a-bd72-3b48581db06b",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d112fbb7-8d5d-4c38-a15d-38ce4642fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_1.drop(['satisfaction'], axis = 1)\n",
    "y = age_1['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8916f30-aed0-4f10-ae71-5cc1396cf805",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196c978-6051-4346-8dca-99128f031171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaffa1f7-050e-4d3f-a8ef-70e5a23e7571",
   "metadata": {},
   "source": [
    "### Best model for Age group 1 data = Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08897f35-a072-46ca-9716-3345224cd96d",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e34c345-bac3-444c-85d6-1b87265a0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gbc = gbc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_gbc, labels = gbc.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = gbc.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c56b31-ad92-4154-950e-65d43a459324",
   "metadata": {},
   "source": [
    "## Age group 2: 19 - 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f947e80b-6d85-4d81-80c0-9d164eeb83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_2 = airline[(airline['Age'] > 18) & (airline['Age'] <= 24)]\n",
    "age_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeac9a6-0583-466f-818a-bb164562ecf5",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ab3a26-cd83-4744-b4c4-d540eefb3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_2.drop(['satisfaction'], axis = 1)\n",
    "y = age_2['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4130e577-c6ab-44d1-9660-cd052a61a98a",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718596c3-cda6-475d-a1db-a23b880968d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa00852-9bf8-49e9-97e6-fc60049a87e2",
   "metadata": {},
   "source": [
    "### Best model for Age group 2 data = Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5497f91-948c-4cd5-927a-62cbd57931b2",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661772a-f372-4ffd-bfd1-9a4a9dd2d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rand_forest = rand_forest_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rand_forest, labels = rand_forest_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = rand_forest_model.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7874507f-dc6c-42ca-b0c8-3f2e20485f85",
   "metadata": {},
   "source": [
    "## Age group 3: 25 - 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0455476-faed-4db9-8ddf-20e423c9c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_3 = airline[(airline['Age'] > 25) & (airline['Age'] <= 34)]\n",
    "age_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1728636c-baec-4f76-b1e1-af4466c4f452",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb319f18-4bac-437b-93c9-c6d04d718089",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_3.drop(['satisfaction'], axis = 1)\n",
    "y = age_3['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5424e691-d222-4afd-8137-26d1253ee720",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4e8a4-9d57-4081-8bad-92aca81a677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef71f3d-bc63-4494-8ac9-97fe1964883d",
   "metadata": {},
   "source": [
    "### Best model for Age group 3 data = Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe15a2-710a-4ec2-9638-2c5a6c57499f",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac310e4b-7592-4d30-89d3-ecc2574c3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rand_forest = rand_forest_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rand_forest, labels = rand_forest_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = rand_forest_model.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a2a27d-4518-44de-b2b2-23985e488050",
   "metadata": {},
   "source": [
    "## Age group 4: 35 - 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c80a150-4f0a-49b2-b921-547e4f435494",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_4 = airline[(airline['Age'] > 35) & (airline['Age'] <= 44)]\n",
    "age_4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b3d7e-da92-4177-89db-aa1b774e3003",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f0f27-8282-464a-9ef1-9c51d8dd376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_4.drop(['satisfaction'], axis = 1)\n",
    "y = age_4['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83ff98-6d2e-49a8-984a-a5981dde85dd",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366d3d4-4e55-4c24-b597-efce45545778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41028bf2-602e-487f-bee8-8cdf1d8fd164",
   "metadata": {},
   "source": [
    "### Best model for Age group 4 data = Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7065739-c251-48f7-837f-df06f9b3cf45",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298d2c7-8dcd-46a3-8a13-5cf0cade3995",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rand_forest = rand_forest_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rand_forest, labels = rand_forest_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = rand_forest_model.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c95ad-35a5-4b29-b180-485c7647d63e",
   "metadata": {},
   "source": [
    "## Age group 5: 45 - 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af8f0f-5cae-4da1-a83b-f1416e1fbaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_5 = airline[(airline['Age'] > 45) & (airline['Age'] <= 54)]\n",
    "age_5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbf9e19-03ea-4d66-ae99-44f06adbae83",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d28f3d-8fce-4284-931c-9b869d312cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_5.drop(['satisfaction'], axis = 1)\n",
    "y = age_5['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c17d2-42c7-442b-9528-1c9dd927cdce",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa467a2-cbe9-4b69-95ae-2a2ea6eb8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e653c-1209-4556-b029-4d7b3ee823b5",
   "metadata": {},
   "source": [
    "### Best model for Age group 5 data = Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04b510-b4bc-4843-a01d-42240d121b2a",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c65312-137f-434c-bf60-18359538e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rand_forest = rand_forest_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rand_forest, labels = rand_forest_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = rand_forest_model.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f7daf-b5a4-4289-a907-470e818b36d9",
   "metadata": {},
   "source": [
    "## Age group 6: 55 - 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76f333e-95bf-4ae6-a5af-3cb28d10cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_6 = airline[(airline['Age'] > 55) & (airline['Age'] <= 64)]\n",
    "age_6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1577ef-5d55-46e0-bea0-e4a2f69a162c",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32591a7-c413-47a2-894c-b0cbf5ba9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_6.drop(['satisfaction'], axis = 1)\n",
    "y = age_6['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91775e98-4612-4b2c-b895-cf6bcd4f4411",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2abd02-e6b3-4f15-ab3f-6de59571556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0cab58-a9c9-4fa9-9ddc-8521ece4dc25",
   "metadata": {},
   "source": [
    "### Best model for Age group 6 data = Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f42741-a678-44c2-87d2-d1ad097c139c",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab1e85-3975-4b1f-94b0-14796ca8272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gbc = gbc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_gbc, labels = gbc.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = gbc.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a108e34-a0a0-4a49-9756-d0149772210b",
   "metadata": {},
   "source": [
    "## Age group 7: above 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf71717-5a04-4529-bbac-1600da08ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_7 = airline[(airline['Age'] >= 65)]\n",
    "age_7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff1810d-87e1-4c06-bfa7-80786918eb8c",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a314dc-b7f8-4ab9-99e5-85c2bdc0bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_7.drop(['satisfaction'], axis = 1)\n",
    "y = age_7['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f850f9-2a66-4146-b901-472a2d542c0b",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce39612-8f25-45bf-b84f-0886f2f93ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6fbbd5-97d5-4b19-89ec-d3ce2296e101",
   "metadata": {},
   "source": [
    "### Best model for Age group 7 data = Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab34ed9-4278-4d7f-95b8-26c1d7280bb7",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b828774c-da27-4b49-bf40-648b2a1fb8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gbc = gbc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_gbc, labels = gbc.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = gbc.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a89069-4430-428c-aabd-3522298c88e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38acf792-b5f4-4a37-ab93-6c493e8fb6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1671f85-e8f8-4aba-99e5-327bea5b14ee",
   "metadata": {},
   "source": [
    "# Subsetting data by Type of Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a3ddbc-1edd-4730-9acc-fc21eda73a46",
   "metadata": {},
   "source": [
    "## Business Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef2956-8c7c-42f0-be63-aa26ca50f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "btravel = airline[airline['Type of Travel'] == 0]\n",
    "btravel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb551a28-8d62-46cc-b0ed-56afe22dfabf",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c04df-5245-405a-b639-46d8bb1e311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = btravel.drop(['satisfaction'], axis = 1)\n",
    "y = btravel['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a5a1d-c6cc-4174-928c-0e82061692f9",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef8a74-99ca-4ed8-a1cd-ffcfcc149ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b448de64-473e-4590-b43f-288158dbe5ed",
   "metadata": {},
   "source": [
    "### Best model for Business Travel data = Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d6b5c9-b96a-40eb-8cb9-05fb6ffe30d7",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21b0a3-5af9-4471-b622-e01fbb62c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rand_forest = rand_forest_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rand_forest, labels = rand_forest_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = rand_forest_model.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1df7a0-379e-4cf0-931b-f46c56c9d7a0",
   "metadata": {},
   "source": [
    "## Personal Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d7023-0224-470c-80fb-c9f6279759dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptravel = airline[airline['Type of Travel'] == 1]\n",
    "ptravel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a1a3b5-c251-41ab-8e61-28d47bb3f748",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac9ba3-38de-4cf9-a53d-d60eb39199a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ptravel.drop(['satisfaction'], axis = 1)\n",
    "y = ptravel['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae82b3-6489-4967-aadb-11ae3f3ba791",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f110d7-0c3d-444d-9b42-bcf5168fd530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422b3dbf-8ea9-4067-a0ed-56f32d5505af",
   "metadata": {},
   "source": [
    "### Best model for Personal Travel data = Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1cabd4-cf9c-4dfd-a8da-347b67837bfb",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d67a84-5758-4037-9a95-5bb1f26ff007",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gbc = gbc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_gbc, labels = gbc.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = gbc.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087cc55-0f72-40cf-9330-14b3568021ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19baf9a9-9e7a-4ccf-9820-fa7b8c3d9145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94b4ca4c-cc8b-4a42-aaaa-691f8d196de0",
   "metadata": {},
   "source": [
    "# Subsetting by Customer Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a858acce-c5a1-4e3c-8417-c37388fc2f14",
   "metadata": {},
   "source": [
    "## Loyal Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de321e1-dabb-488b-bd35-cfed90ddb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loyal = airline[airline['Customer Type'] == 0]\n",
    "loyal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702fecb7-b454-45cf-aeb4-c9329e756e88",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc814f6-6bba-45b2-afea-605488beffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loyal.drop(['satisfaction'], axis = 1)\n",
    "y = loyal['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a336624-433f-4c80-8b68-471e9959284a",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8c899d-cc1a-4f83-b16a-9f3cf7308866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877ef2f5-9217-475b-8127-703d65e3b53e",
   "metadata": {},
   "source": [
    "### Best model for Loyal Customer data = Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034e9f67-abcb-48d3-90c2-559b93e24f58",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723c2a6-79d5-4357-9ab8-93089f904f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rand_forest = rand_forest_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rand_forest, labels = rand_forest_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = rand_forest_model.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2004a63e-5cd6-4513-8eef-cb22ff63cea5",
   "metadata": {},
   "source": [
    "## Disloyal Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a999e4f-e345-4616-b235-114c2cb6f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disloyal = airline[airline['Customer Type'] == 1]\n",
    "disloyal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd8f824-97b5-49a5-89f0-72d1b6735135",
   "metadata": {},
   "source": [
    "### Test-Train Split (40:60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705758e-58ff-4205-ad08-c80b3fa322ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = disloyal.drop(['satisfaction'], axis = 1)\n",
    "y = disloyal['satisfaction']\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25608077-4a08-461c-9542-c970bf36ac21",
   "metadata": {},
   "source": [
    "### Comparing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf31b2f5-e93c-47cb-a051-ca4ef6da6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log\n",
    "log_model = LogisticRegression(random_state = 0).fit(X_train, y_train)\n",
    "#decision tree score\n",
    "depth_list = np.arange(1, 20, 1)\n",
    "scores_list = [cross_val_score(DecisionTreeClassifier(max_depth = depth, criterion='gini', random_state = 0), \n",
    "                               X_train, y_train, cv = 10, scoring = 'accuracy').mean() for depth in depth_list]\n",
    "best_depth = max(range(len(scores_list)), key = lambda x: scores_list[x]) + 1\n",
    "dt_model = DecisionTreeClassifier(max_depth = best_depth, criterion = \"gini\", random_state = 0).fit(X_train, y_train)\n",
    "#bagging\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_bag = BaggingClassifier(n_estimators = 10, random_state = 0).fit(X_train_scaled, y_train)\n",
    "#random forest\n",
    "rand_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42).fit(X_train, y_train)\n",
    "#gradient boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X, y)\n",
    "\n",
    "\n",
    "#for comparing all the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', log_model))\n",
    "models.append(('Decision Tree Classifier', dt_model))\n",
    "models.append(('Bagging Classifier', clf_bag))\n",
    "models.append(('Random Forest Classifier', rand_forest_model))\n",
    "models.append(('Gradient Boosting Classifier', gbc))\n",
    "models.append(('KNN', knn))\n",
    "\n",
    "#evaluating model results\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "#set table to table to populate with perf results\n",
    "col = ['Algorithm', 'AUC Mean', 'AUC STD', 'Accuracy Mean', 'Accuracy STD']\n",
    "model_results = pd.DataFrame(columns = col)\n",
    "\n",
    "\n",
    "\n",
    "#using k-fold cross-validation:\n",
    "i = 0\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 3)\n",
    "    # accuracy scoring:\n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    # roc_auc scoring:\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n",
    "    #append\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "\n",
    "#results\n",
    "model_results.sort_values(by = ['AUC Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28fedd0-2caa-473b-9bed-667d624e7f7c",
   "metadata": {},
   "source": [
    "### Best model for Disloyal Customer data = Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6a656-5aeb-4f61-b0b1-03dcb8cc2595",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5904c23-54cb-4c94-a88e-477f6e19d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gbc = gbc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_gbc, labels = gbc.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = gbc.classes_)\n",
    "disp.plot(cmap = 'flare') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bece40-dad2-452c-b1be-e8296f986643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc4a2a-1c98-49f1-990d-c27f2b06d477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bf034e5-1559-480b-a74d-503792bd993c",
   "metadata": {},
   "source": [
    "# Business Decision Performance\n",
    "\n",
    "- We are choosing the model that performs best for each subset and choosing the top 3 most important features (based on the model)\n",
    "- Increasing the satisfaction by 1 for each of those features and predicting (based on test data) how many passengers that were initially dissatified, [since most of the model accuracies are above 97%, assuming the predictions are true] will be predicted as satisfied\n",
    "- Then calculating the cost, profit and the cost profit ratio for each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f08689-3354-4bef-a7bc-701a5e6e1bdf",
   "metadata": {},
   "source": [
    "## Assumed costs for increasing a variable by 1 unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea93d8-6636-4e3b-a3d0-fa2b313d34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = {\n",
    "    'Flight Distance': 400, 'Inflight wifi service': 80, 'Ease of Online booking': 60,\n",
    "    'Gate location': 140, 'Food and drink': 100, 'Online boarding': 70, 'Seat comfort': 110,\n",
    "    'Inflight entertainment': 50, 'On-board service': 30, 'Leg room service': 500,\n",
    "    'Baggage handling': 20, 'Checkin service': 20, 'Inflight service': 40, 'Cleanliness': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3942394-575d-481a-aaaa-177c6bfc3e23",
   "metadata": {},
   "source": [
    "## Assumed profit per changed customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f80da-3653-4caf-8571-a43360e9eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_per_change = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e1841-6e0b-4718-8b55-1b89b22452e8",
   "metadata": {},
   "source": [
    "## For Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3b489f-0273-4470-8be4-e9aa1d8fe16f",
   "metadata": {},
   "source": [
    "### For Business Class: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dbbce1-ac83-44f5-8d21-6acee1182f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#business.head()\n",
    "X = business.drop(['satisfaction'], axis = 1) \n",
    "y = business['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced5b9e-c52f-4b8e-8144-e1ae91101a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ebd28-56cc-4fa9-8fe2-4b20132be04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(rf,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fabc4a-061a-42be-a8ba-ccb25eea8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = business.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = business['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a9dbc-3806-4a8a-9fd7-5cceb01244cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "rf = RandomForestClassifier(random_state = 0).fit(X_train,y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a0cde3-d5e3-43a1-998a-f4ab00677ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bbbb53-f0df-46b8-a2e8-20425837722f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase = rf.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_business_class = pd.DataFrame(table_data, columns=table_head)\n",
    "results_business_class[\"Cost Benefit ($)\"] = results_business_class[\"Total Profit ($)\"]/results_business_class[\"Total Cost ($)\"]\n",
    "results_business_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bd83b-9274-4890-b3fd-661c325de4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2611f46f-8757-475c-b5c1-9866bb2bdd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_business_class, color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace3de4-1f8d-4b72-ad6f-3b09d2a9f72d",
   "metadata": {},
   "source": [
    "### For Economy Class: Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26c9570-c17f-4092-90a9-0c14439b5922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = economy.drop(['satisfaction'], axis = 1) \n",
    "y = economy['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f3ae2-db38-45d4-a4ad-dd3e39a13632",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e465a88-f86e-4b5d-9df4-6e90dd6699ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(rf,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d0356-cba7-4bbd-94e4-2416fb0e55f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = economy.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = economy['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5482287-acdb-4584-babb-a2f28900a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "rf = RandomForestClassifier(random_state = 0).fit(X_train,y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b524cd-baee-4636-b644-4530da4fabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16570850-864a-4534-9872-79913f27acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = rf.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_economy_class = pd.DataFrame(table_data, columns=table_head)\n",
    "results_economy_class[\"Cost Benefit ($)\"] = results_economy_class[\"Total Profit ($)\"]/results_economy_class[\"Total Cost ($)\"]\n",
    "results_economy_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce0014-c4ba-49e0-8e75-da5349e81b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_economy_class, color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b89d38b-cab8-4185-9df9-4ba316c66623",
   "metadata": {},
   "source": [
    "### For Economy Plus Class: Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e777f3-46a9-441a-b1a6-e5f3dab09107",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = economy_plus.drop(['satisfaction'], axis = 1) #dropping no common class for non important stuff\n",
    "y = economy_plus['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0121a8-7b28-4b31-8b31-79345113a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42)\n",
    "gb.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,gb.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ca642-89ac-4f13-b36c-51c07a5cc91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(gb,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33858158-f6f3-40c5-bbc8-9a51cbfbfbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = economy_plus.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = economy_plus['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6abe40-a151-49b5-8138-29cdf77be2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "gb = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,gb.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5dbe2b-99e9-4eca-98e4-4c50d6150e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce290f-e552-4b3d-97f7-0e6c0f2a0024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = gb.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_economy_plus_class = pd.DataFrame(table_data, columns=table_head)\n",
    "results_economy_plus_class[\"Cost Benefit ($)\"] = results_economy_plus_class[\"Total Profit ($)\"]/results_economy_plus_class[\"Total Cost ($)\"]\n",
    "results_economy_plus_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b72519-a933-4cf4-84d8-8e07e4aed0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_economy_plus_class, color='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6353eb74-8db6-4080-bc01-4879eb97907a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee9d9bc-07cf-4ea1-b917-5e8871503828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faebed6c-5bb8-4967-9176-886dc933159b",
   "metadata": {},
   "source": [
    "## For Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d055362-5949-4aef-8450-3c1e65964579",
   "metadata": {},
   "source": [
    "### For Female data: Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d1f3c-5719-4adc-8c9d-0e8a5f17f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = female.drop(['satisfaction'], axis = 1) \n",
    "y = female['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4ec75-9705-4ad4-ab58-70f874e9fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c3fef0-2ae1-411a-b44f-9e5cee05da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(rf,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c7758a-af70-4103-bb81-0d579a9a67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = female.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = female['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d09a792-2ac8-409b-a8da-acbfb930de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "rf = RandomForestClassifier(random_state = 0).fit(X_train,y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39090a7f-e1a1-4caa-aded-b443b63a4d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d91fd2-4992-4954-97fb-40a9829d32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = rf.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_female_class = pd.DataFrame(table_data, columns=table_head)\n",
    "results_female_class[\"Cost Benefit ($)\"] = results_female_class[\"Total Profit ($)\"]/results_female_class[\"Total Cost ($)\"]\n",
    "results_female_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216cf03-195f-4a86-909f-bac15dc3a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_female_class, color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fabaff-bb99-46c2-b8df-f1a03a3d64e4",
   "metadata": {},
   "source": [
    "### For Male data: Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd61fba9-4e9d-4cfb-b288-35bd744eb26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = male.drop(['satisfaction'], axis = 1) \n",
    "y = male['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55789f-e9c0-4999-a2b4-41ae7b9c5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3af87c-1223-47fc-98f7-2624bf42b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(rf,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763d462-adc3-4ed0-883f-ca6b3232d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = male.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = male['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549731d4-cdb9-4a30-8924-2484c509345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "rf = RandomForestClassifier(random_state = 0).fit(X_train,y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96fc11-e6f5-4dfa-afa0-7d97f4840c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3da591-eda6-4018-9869-b120adf1a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = rf.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_male_class = pd.DataFrame(table_data, columns=table_head)\n",
    "results_male_class[\"Cost Benefit ($)\"] = results_male_class[\"Total Profit ($)\"]/results_male_class[\"Total Cost ($)\"]\n",
    "results_male_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8f061-1b12-4e35-bfb0-a9e7d9ec55fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_male_class, color='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be4cf3-0eae-4bc5-9430-0bd006259a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97413dbb-8932-41aa-b7b9-1b736a0e7c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16974966-05a0-4de8-9875-172e4d321f85",
   "metadata": {},
   "source": [
    "## For Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cdc93b-340b-4151-b321-f2685e703fa1",
   "metadata": {},
   "source": [
    "### For Age group 1(6-18): Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f019a29-49e4-4ad0-ad91-bfa6b4494756",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_1.drop(['satisfaction'], axis = 1) \n",
    "y = age_1['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b38f82-593d-40af-a97d-8b24999ba422",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42)\n",
    "gb.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,gb.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939612b-14d8-49b8-9aa3-8e799741d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(gb,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f81d3-ff67-4c64-acde-664f77cab498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = age_1.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = age_1['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f49522-41f6-4328-a32c-2f46bd2e426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "gb = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,gb.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9df5b1-ad54-43fe-b189-0490f0e755c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33bafb1-9a45-42df-b57e-9ccd1d1bf675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = gb.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_age_1_class = pd.DataFrame(table_data, columns=table_head)\n",
    "results_age_1_class[\"Cost Benefit ($)\"] = results_age_1_class[\"Total Profit ($)\"]/results_age_1_class[\"Total Cost ($)\"]\n",
    "results_age_1_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc226c3-42c3-41a0-a50f-bbe05f67907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_age_1_class, color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f358e217-904a-4dd3-a61f-e5b0dd5eed89",
   "metadata": {},
   "source": [
    "### For Age group 2(19-24): Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f40c9d-c924-4aff-95e6-da42b320ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_2.drop(['satisfaction'], axis = 1) \n",
    "y = age_2['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd94479-17c2-44a3-ba51-3d022d15ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05028c1-e32d-4d71-9f93-15f13fc6a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(rf,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5013269e-b095-4da3-a238-63b1e7360c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = age_2.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = age_2['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53a311-605d-47b0-b199-bb4b1c7981d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "rf = RandomForestClassifier(random_state = 0).fit(X_train,y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbeebb2-0b5e-412c-9b14-17ba541e0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d26c1-84ea-468d-b829-ab406a2161ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = rf.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_age_2_class = pd.DataFrame(table_data, columns=table_head)\n",
    "results_age_2_class[\"Cost Benefit ($)\"] = results_age_2_class[\"Total Profit ($)\"]/results_age_2_class[\"Total Cost ($)\"]\n",
    "results_age_2_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b4ec94-ddb8-414e-8fb6-4c68ec341aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_age_2_class, color='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66247e24-9d49-40c1-a9e0-e0458e064e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "776ad097-3da5-4bcc-b05c-2747286c0d7b",
   "metadata": {},
   "source": [
    "### For Age group 3(25-34): Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1aa286-6abc-49ad-89c2-c4591a2dfcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_3.drop(['satisfaction'], axis = 1) \n",
    "y = age_3['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f3e61-f5a0-4d09-99ce-2fd15389ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3705b1-e67e-4902-8171-cb7319900a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(rf,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e2203-c8dd-4b9c-a92c-e927330975ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = age_3.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = age_3['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7910fb-4b57-40bb-b49d-0064a54e727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "rf = RandomForestClassifier(random_state = 0).fit(X_train,y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ea10a8-3988-4fe7-8940-88fb72b225c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d397a1c5-235e-4bc3-98fe-c5000cedb3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = rf.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_age_3_class = pd.DataFrame(table_data, columns=table_head)\n",
    "results_age_3_class[\"Cost Benefit ($)\"] = results_age_3_class[\"Total Profit ($)\"]/results_age_3_class[\"Total Cost ($)\"]\n",
    "results_age_3_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e751d56d-0a11-4e16-a506-e8c43b0d6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_age_3_class, color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01916ca-b267-4584-892a-8cedfed61aea",
   "metadata": {},
   "source": [
    "### For Age group 4(35-44): Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca758d-5dfc-48b5-bb9d-6a09a3176bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_4.drop(['satisfaction'], axis = 1) \n",
    "y = age_4['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c7074-af10-4ee5-88ce-a6bfc34b74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9ba39-80ee-4def-8367-c2583b979dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(rf,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03feff2a-2d58-4ccb-a5f4-ff11e0eb8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = age_4.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = age_4['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c06d9-6c01-4c40-872a-c70269dbf8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "rf = RandomForestClassifier(random_state = 0).fit(X_train,y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca1299a-f303-42ed-bc66-afbcadfddb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e8a58-42be-4821-9663-d067d758c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = rf.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_age_4_class = pd.DataFrame(table_data, columns=table_head)\n",
    "results_age_4_class[\"Cost Benefit ($)\"] = results_age_4_class[\"Total Profit ($)\"]/results_age_4_class[\"Total Cost ($)\"]\n",
    "results_age_4_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac33db-880b-47e8-9be0-c3d3558a044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_age_4_class, color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7215d9be-1a18-4779-911e-188a791c7f63",
   "metadata": {},
   "source": [
    "### For Age group 5(45-54): Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705260f-df59-409f-8a42-f624ca2fa68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_5.drop(['satisfaction'], axis = 1) \n",
    "y = age_5['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f52b6-9422-4181-a6eb-6ef63f096d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92bce85-101a-421a-b433-b1523a05f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(rf,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664113be-cf51-4fcd-867c-b1426c648851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = age_5.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = age_5['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02f7df1-2b04-4476-b85f-65e94631870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "rf = RandomForestClassifier(random_state = 0).fit(X_train,y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eeb37f-6b9c-4aa7-86f6-8830750fbade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98993e6e-9583-46db-b458-aa6a8e009dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = rf.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_age_5_class = pd.DataFrame(table_data, columns=table_head)\n",
    "results_age_5_class[\"Cost Benefit ($)\"] = results_age_5_class[\"Total Profit ($)\"]/results_age_5_class[\"Total Cost ($)\"]\n",
    "results_age_5_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7177098f-e3aa-4438-bc6e-171fe27264f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_age_5_class, color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce86a8-da55-4861-9dc3-e1e572ca4e8e",
   "metadata": {},
   "source": [
    "### For Age group 6(55-64): Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028dac49-a1df-464b-b8db-7607381aab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_6.drop(['satisfaction'], axis = 1) \n",
    "y = age_6['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf5d96-4464-4718-bee3-0f0498996120",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,gb.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41efc2a2-cc6c-4b2f-8854-189d0b52d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(gb,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd71acc7-8b46-4321-9dcc-68b00ecfc9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = age_6.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = age_6['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee2a695-752a-4722-8044-379dae41ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "gb = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,gb.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1904cf-5186-432c-8176-a219a6038f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109ac9b-b2b6-4b60-bcaf-30247978fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = gb.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_age_6_class = pd.DataFrame(table_data, columns=table_head)\n",
    "results_age_6_class[\"Cost Benefit ($)\"] = results_age_6_class[\"Total Profit ($)\"]/results_age_6_class[\"Total Cost ($)\"]\n",
    "results_age_6_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422370c-5d5d-454b-bdf2-f5fc1c3b53c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_age_6_class, color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63236511-715c-42ed-8ae0-4cd27e0ab3dd",
   "metadata": {},
   "source": [
    "### For Age group 7(above 65): Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d5ad8-4be7-433b-822f-930b6e770d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = age_7.drop(['satisfaction'], axis = 1) \n",
    "y = age_7['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae28653-323c-46dd-824a-2ba229b29418",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,gb.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be2a933-fa28-4bf0-8c35-05e4e8819a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(gb,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea0063-fe25-427c-a9d2-b9743718141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = age_7.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = age_7['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f524c-0413-4efa-a243-d2a25d9a21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "gb = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,gb.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff100ae4-dbcb-4db2-a97d-52d53fe62209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b836e6-4f4c-4ff9-8c48-b588d6d01048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = gb.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_age_7_class = pd.DataFrame(table_data, columns=table_head)\n",
    "results_age_7_class[\"Cost Benefit ($)\"] = results_age_7_class[\"Total Profit ($)\"]/results_age_7_class[\"Total Cost ($)\"]\n",
    "results_age_7_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c9287-e11c-4283-854f-81812ad38af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_age_7_class, color='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5c70a-05cc-438c-8b0c-f9915d459ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d31f00-468d-4a1c-aefc-75f1bb2ad1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "568c5a17-302a-47be-8a98-be959dcb3884",
   "metadata": {},
   "source": [
    "## For Type of Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bd3fea-f804-449c-a231-41af21261410",
   "metadata": {},
   "source": [
    "### For Business Travel: Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19978c73-9f66-4536-bcdf-bac2d7a13373",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = btravel.drop(['satisfaction'], axis = 1) \n",
    "y = btravel['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377526d8-6562-484a-8bc5-97f002c380e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92868b70-92fa-4c3b-9c31-806aec6f8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(rf,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d092692-8c20-4c41-a1c4-3d33f5e0292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = btravel.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = btravel['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b79bc84-60a6-4071-b897-edf099874082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "rf = RandomForestClassifier(random_state = 0).fit(X_train,y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab722cd-fe7d-4173-bec0-de10dc508086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933d8e1-743d-43fc-86ab-1bfc60cda408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = rf.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_btravel = pd.DataFrame(table_data, columns=table_head)\n",
    "results_btravel[\"Cost Benefit ($)\"] = results_btravel[\"Total Profit ($)\"]/results_btravel[\"Total Cost ($)\"]\n",
    "results_btravel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88b7cb-bf95-46bd-853a-95f1a44ee191",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_btravel, color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3eb93b-a9be-4c2d-bbb9-f46016f4aec1",
   "metadata": {},
   "source": [
    "### For Personal Travel: Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954b0e8-d0e2-42df-8990-a95a3162db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ptravel.drop(['satisfaction'], axis = 1) #dropping no common class for non important stuff\n",
    "y = ptravel['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d237ee6-b9e9-4c71-908e-6d7882d9144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42)\n",
    "gb.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,gb.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb89d6-4900-44cb-be90-22f7977a4a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(gb,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac7edd-085f-43f6-b3ee-5ba88646c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = ptravel.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = ptravel['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76cd744-667f-4b85-bfb0-986d6448557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "gb = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,gb.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbcac09-8824-4df7-a893-5c358e92a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef39d5a3-a755-4725-8284-7e5c6ffc46e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = gb.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_ptravel = pd.DataFrame(table_data, columns=table_head)\n",
    "results_ptravel[\"Cost Benefit ($)\"] = results_ptravel[\"Total Profit ($)\"]/results_ptravel[\"Total Cost ($)\"]\n",
    "results_ptravel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade28299-057b-4d21-a229-482f05ca7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_ptravel, color='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c2a3e-17d3-46e1-8e87-f72c939afbfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e72e57d-966f-407e-96a6-0a42669a07ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3a5fa4a-db91-47ca-8ac6-557e99ede3a4",
   "metadata": {},
   "source": [
    "## For Type of Customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d3619-91b1-4787-abf0-d7909b7c79e1",
   "metadata": {},
   "source": [
    "### For Loyal Customer: Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f3290e-46cb-4021-846f-24e42894e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loyal.drop(['satisfaction'], axis = 1) \n",
    "y = loyal['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa7f420-0da8-4974-b255-8f545acaa303",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ad0f2-695d-48ae-8c29-19d433296a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(rf,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fcf697-35db-4940-8690-de3eb27d9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = loyal.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = loyal['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720ff6d-7c9b-4ed9-8aed-baa311e87757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "rf = RandomForestClassifier(random_state = 0).fit(X_train,y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf4891-0ac5-4738-8549-8b254ddc64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f07a1a-44f3-4dc1-9977-58fc2429090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = rf.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_loyal = pd.DataFrame(table_data, columns=table_head)\n",
    "results_loyal[\"Cost Benefit ($)\"] = results_loyal[\"Total Profit ($)\"]/results_loyal[\"Total Cost ($)\"]\n",
    "results_loyal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8bf67c-cab6-412a-beb0-c2f2d6908126",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_loyal, color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec06a0-d515-4885-a740-b256fbaeaf1d",
   "metadata": {},
   "source": [
    "### For Disloyal Customer: Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97418874-f575-4d0b-956d-855bd7eb4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = disloyal.drop(['satisfaction'], axis = 1) #dropping no common class for non important stuff\n",
    "y = disloyal['satisfaction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeb00d4-3592-4c20-bb65-b5801d8cb623",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42)\n",
    "gb.fit(X_train,y_train)\n",
    "\n",
    "#checking current feature importances\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "f_i = list(zip(features,gb.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8499a9f9-b4bf-4b89-a6c6-3eafca792565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination \n",
    "rfe = RFECV(gb,cv = 2,scoring = \"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "#to check for columns that have been removed\n",
    "selected_features = np.array(features)[rfe.get_support()]\n",
    "features = X_test.columns\n",
    "no_common = [value for value in features if value not in selected_features]\n",
    "no_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd362c0-b7ee-40c2-ac38-7a4f817370c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data again with the removed features\n",
    "X = disloyal.drop(['satisfaction'] + no_common, axis = 1) #dropping no common class for non important stuff\n",
    "y = disloyal['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) #40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9fab6-d714-43dd-b5a3-24d2890d9ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using new infor\n",
    "gb = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42).fit(X_train, y_train)\n",
    "features = X.columns\n",
    "\n",
    "#plot\n",
    "f_i = list(zip(features,gb.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i], color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaaddde-0c51-4f23-9bf8-f85b3ed36c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intital predictions\n",
    "initial_predictions = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5fcc6-8b93-4956-b6d4-9cb617d7d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 3 features that have higher importance in model\n",
    "top3 = [f[0] for f in sorted(f_i, key=lambda x: x[1], reverse=True)[:3]] \n",
    "excluded = no_common #exluding columns that are removed with recursive feature elimination\n",
    "increased_values = 1 #increasing satisfaction by 1\n",
    "profits = [] #to store profits\n",
    "table_data = []\n",
    "\n",
    "for feature in top3:\n",
    "    X_test_increase = X_test.copy()\n",
    "    total_cost = 0\n",
    "\n",
    "    if feature not in excluded:\n",
    "        X_test_increase[feature] = X_test_increase[feature].apply(lambda x: min(x + increased_values, max_value))\n",
    "        cost = costs.get(feature, 0) * increased_values\n",
    "        total_cost += cost\n",
    "\n",
    "    y_pred_increase_new = gb.predict(X_test_increase) #new predictions\n",
    "    \n",
    "    changed = sum((y_test == 0) & (y_pred_increase_new == 1)) #to see how many changed from dissatisfied to satisfied\n",
    "    profit = profit_per_change * changed #profit per changed customer\n",
    "    profits.append(profit)\n",
    "    table_data.append([feature, increased_values, total_cost, profit, changed])\n",
    "\n",
    "table_head = [\"Feature\", \"Increased Value\", \"Total Cost ($)\", \"Total Profit ($)\", \"Number of Changes\"]\n",
    "results_disloyal = pd.DataFrame(table_data, columns=table_head)\n",
    "results_disloyal[\"Cost Benefit ($)\"] = results_disloyal[\"Total Profit ($)\"]/results_disloyal[\"Total Cost ($)\"]\n",
    "results_disloyal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b34e1b-6d0f-4d47-b9a5-c52c39dfb29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.barplot(x='Feature', y='Cost Benefit ($)', data = results_disloyal, color='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff97e92-533c-4190-8f3f-daa9c3c352a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c28f6f-6467-4cda-a1e9-1869b16e1943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b229ec7-fe64-48e9-96ee-06be15263844",
   "metadata": {},
   "source": [
    "# Other visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bda8a9-ff07-4dd8-b3d3-1e73ecb16ce6",
   "metadata": {},
   "source": [
    "## Total profits over different Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b22fb9a-918c-40b5-b832-4319cf1049e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_profit_business_class = results_business_class[\"Total Profit ($)\"].sum()\n",
    "total_profit_economy_class = results_economy_class[\"Total Profit ($)\"].sum()\n",
    "total__economy_plus_class = results_economy_plus_class[\"Total Profit ($)\"].sum()\n",
    "\n",
    "profits = [total_profit_business_class, total_profit_economy_class, total__economy_plus_class]\n",
    "labels = [\"Business Class\", \"Economy Class\", \"Economy Plus Class\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x = labels, y = profits, palette = \"pink\")\n",
    "plt.ylabel(\"Total Profit ($)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95071611-6d29-4596-8099-070408ac10a7",
   "metadata": {},
   "source": [
    "## Total profits over different Genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701d1fa8-975a-4598-975b-5038b5f748e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_profit_female = results_female_class[\"Total Profit ($)\"].sum()\n",
    "total_profit_male = results_male_class[\"Total Profit ($)\"].sum()\n",
    "\n",
    "profits = [total_profit_female, total_profit_male]\n",
    "labels = [\"Female\", \"Male\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x = labels, y = profits, palette = \"Reds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a359288c-2545-4e9e-80a2-929fae36036e",
   "metadata": {},
   "source": [
    "## Total profits over different Age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebf373-c3d1-4be3-9f6d-1243dff1633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_profit_age1 = results_age_1_class[\"Total Profit ($)\"].sum()\n",
    "total_profit_age2 = results_age_2_class[\"Total Profit ($)\"].sum()\n",
    "total_profit_age3 = results_age_3_class[\"Total Profit ($)\"].sum()\n",
    "total_profit_age4 = results_age_4_class[\"Total Profit ($)\"].sum()\n",
    "total_profit_age5 = results_age_5_class[\"Total Profit ($)\"].sum()\n",
    "total_profit_age6 = results_age_6_class[\"Total Profit ($)\"].sum()\n",
    "total_profit_age7 = results_age_7_class[\"Total Profit ($)\"].sum()\n",
    "\n",
    "profits = [total_profit_age1, total_profit_age2, total_profit_age3, total_profit_age4, total_profit_age5, total_profit_age6, \n",
    "           total_profit_age7]\n",
    "labels = [\"Age group 1\", \"Age group 2\", \"Age group 3\", \"Age group 4\", \"Age group 5\", \"Age group 6\", \"Age group 7\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x = labels, y = profits, palette = \"Purples\")\n",
    "plt.ylabel(\"Total Profit ($)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f1c6bd-5efe-45ca-a987-e40e2863d47e",
   "metadata": {},
   "source": [
    "## Total profits over different Type of Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182849a2-e070-4544-bcf3-93434dfd516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_profit_btravel = results_btravel[\"Total Profit ($)\"].sum()\n",
    "total_profit_ptravel = results_ptravel[\"Total Profit ($)\"].sum()\n",
    "\n",
    "profits = [total_profit_btravel, total_profit_ptravel]\n",
    "labels = [\"Business Travel\", \"Personal Travel\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x = labels, y = profits, palette = \"Greens\")\n",
    "plt.ylabel(\"Total Profit ($)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b098888-3b08-40f7-bec8-72171e9d64a3",
   "metadata": {},
   "source": [
    "## Total profits over different Type of Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd072b04-ccfa-40d7-b94e-a9a5195017c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_profit_loyal = results_loyal[\"Total Profit ($)\"].sum()\n",
    "total_profit_disloyal = results_disloyal[\"Total Profit ($)\"].sum()\n",
    "\n",
    "profits = [total_profit_loyal, total_profit_disloyal]\n",
    "labels = [\"Loyal Customer\", \"Disoyal Customer\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x = labels, y = profits, palette = \"Blues\")\n",
    "plt.ylabel(\"Total Profit ($)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363baff1-cd8d-4739-ab7d-f4e0319b3aae",
   "metadata": {},
   "source": [
    "## Overall Profits for different Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab512af-fbe3-4f57-ac90-55432efe65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining results\n",
    "all_results = pd.concat([results_business_class, results_economy_class, results_economy_plus_class,\n",
    "                         results_female_class, results_male_class, \n",
    "                         results_age_1_class, results_age_2_class, results_age_3_class, results_age_4_class, \n",
    "                         results_age_5_class, results_age_6_class, results_age_7_class,\n",
    "                         results_btravel, results_ptravel,\n",
    "                         results_loyal, results_disloyal])\n",
    "\n",
    "all_results = all_results.groupby('Feature').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473631b-e907-4a91-b5be-41904bfd4a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x ='Feature', y ='Total Profit ($)', data = all_results, palette = 'crest')\n",
    "plt.xticks(rotation=45, ha ='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085e378-ef0b-405a-b34f-77513cc2981c",
   "metadata": {},
   "source": [
    "## Overall Costs Benefit for different Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6e0ea-688b-47cf-904f-580fef894f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x ='Feature', y ='Total Cost ($)', data = all_results, palette = 'coolwarm')\n",
    "plt.xticks(rotation=45, ha ='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8932659c-ceb1-458e-9799-fdc5c6fcc839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining results\n",
    "all_results = pd.concat([results_business_class, results_economy_class, results_economy_plus_class,\n",
    "                         results_female_class, results_male_class, \n",
    "                         results_age_1_class, results_age_2_class, results_age_3_class, results_age_4_class, \n",
    "                         results_age_5_class, results_age_6_class, results_age_7_class,\n",
    "                         results_btravel, results_ptravel,\n",
    "                         results_loyal, results_disloyal])\n",
    "\n",
    "all_results = all_results.groupby('Feature').sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x ='Feature', y ='Cost Benefit ($)', data = all_results, palette = 'rocket')\n",
    "plt.xticks(rotation=45, ha ='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e066782-f362-4d08-8b90-80710fa935ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73659b36-23f4-4481-ac07-7e3042568932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a5336-8088-4882-8ad8-3732a04c686e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89271f5d-c8f5-4a21-a32e-8e83446ad5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
